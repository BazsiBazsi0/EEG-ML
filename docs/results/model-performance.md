The model performance was evaluated using the following metrics:
- Accuracy
- Precision
- Recall
- F1-score
- ROC curve
- AUC
- Confusion matrix

Additionally every metric was validated using 10-fold cross-validation to ensure the model's performance was not overfitting. The results were averaged, graphed and detailed in the results section. The ROC curve was plotted for each model, and the AUC was calculated. The models were then tested on the test set, and the results were compared to the training set to ensure that the model was not overfitting.